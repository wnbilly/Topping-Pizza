{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Several code snippets for the pizza project\n",
        "\n",
        "The data can be downloaded from the page: http://pizzagan.csail.mit.edu/\n",
        "\n",
        "There are two types of data: synthetic and real. Use the dataset you want, but beware that they do not have the same labels. They were not originally used for label prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "anbqov0swLt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connection to your drive"
      ],
      "metadata": {
        "id": "CVe_zAe1xqdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_WAhuqU4a3D"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "DATA_DIR =  '/content/gdrive/MyDrive/teaching/pizza'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful libraries"
      ],
      "metadata": {
        "id": "CrK4WVZrxuib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "#import shutil\n",
        "\n",
        "import sys\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "# scikitlearn\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "#!pip install torchmetrics\n",
        "#from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "  !nvidia-smi"
      ],
      "metadata": {
        "id": "MPyo4kDBBE-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Managing data"
      ],
      "metadata": {
        "id": "RAO1Og_Ex6Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decompress the archive on Gdrive (rather than on your own desktop)\n",
        "Uncomment the following line to do it."
      ],
      "metadata": {
        "id": "fNpCLsVCvbYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip '/content/gdrive/MyDrive/teaching/pizza/pizzaGANsyntheticdata.zip' -d '/content/gdrive/MyDrive/teaching/pizza/'"
      ],
      "metadata": {
        "id": "eIsyG07Y5QE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read data\n",
        "\n",
        "and build the train and test dataset"
      ],
      "metadata": {
        "id": "KBbxL8vD7tOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_all = np.loadtxt(os.path.join(DATA_DIR, 'syntheticDataset/train/trainLabels.txt'))\n",
        "x_all = np.arange(y_all.shape[0])\n",
        "\n",
        "# Create train, val and test splits\n",
        "# x_train and x_val only contain image number (not the raw data)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_all, y_all, test_size=0.2, random_state=123)\n",
        "\n",
        "print(y_train.shape)\n",
        "\n",
        "y_test = np.loadtxt(os.path.join(DATA_DIR, 'syntheticDataset/test/testLabels.txt'))\n",
        "x_test = np.arange(y_test.shape[0])\n",
        "\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "id": "oHchYgvB-QyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display one sample image"
      ],
      "metadata": {
        "id": "i_iET-ArwB-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 45\n",
        "\n",
        "img_name = \"{:04d}.png\".format(idx+1)\n",
        "print(img_name)\n",
        "\n",
        "img_path = os.path.join(DATA_DIR, 'syntheticDataset/train/images')\n",
        "\n",
        "img = Image.open(os.path.join(img_path, img_name))\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ARQU7VYtKbKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store train images in memory\n",
        "\n",
        "This should make learning faster."
      ],
      "metadata": {
        "id": "tcIdT0Kcy86V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path=os.path.join(DATA_DIR, 'syntheticDataset/train')\n",
        "\n",
        "# Test if the numpy file exists\n",
        "if (os.path.exists(os.path.join(train_data_path, 'img_data_224.npz'))):\n",
        "  img_data_tensor = np.load(os.path.join(train_data_path, 'img_data_224.npz'))\n",
        "  img_all = img_data_tensor['img_data']\n",
        "else:\n",
        "  img_all = []\n",
        "    \n",
        "  for idx in tqdm(x_all):\n",
        "      img_name = \"{:04d}.png\".format(idx+1)\n",
        "      x = Image.open(os.path.join(train_data_path, 'images', img_name))\n",
        "      img_all.append(np.array(x.resize((224,224))))\n",
        "\n",
        "  np.savez_compressed(os.path.join(train_data_path,'img_data_224.npz'), img_data=np.array(img_all))"
      ],
      "metadata": {
        "id": "9ys8lQHwy8XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset class"
      ],
      "metadata": {
        "id": "7EVhot6pCkTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myDataset(Dataset):\n",
        "    \"\"\"Pizza dataset\"\"\"\n",
        "    \n",
        "    def __init__(self, x_idx, y, img_path='/content/gdrive/MyDrive/teaching/pizza/syntheticDataset/train/images', img_data = None, transform=None):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "      \"\"\"\n",
        "      self.x_idx = x_idx\n",
        "      self.y = y\n",
        "      self.img_path = img_path\n",
        "      self.transform = transform\n",
        "      self.img_data = img_data     \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      if isinstance(self.img_data,np.ndarray):\n",
        "        x = Image.fromarray(self.img_data[idx,:,:,:])\n",
        "      else:\n",
        "        img_name = \"{:04d}.png\".format(idx+1)\n",
        "        x = Image.open(os.path.join(self.img_path, img_name))\n",
        "      y = self.y[idx,:]\n",
        "      if self.transform:\n",
        "          x = self.transform(x)\n",
        "      y = np.int64(y)\n",
        "      return x, y\n",
        "            \n",
        "    def __len__(self):\n",
        "        return int(len(self.x_idx))\n"
      ],
      "metadata": {
        "id": "z_l2ChvoCkdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loaders"
      ],
      "metadata": {
        "id": "3HY9LTbR71XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 25\n",
        "\n",
        "input_size = 224\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.RandomVerticalFlip(),\n",
        "                                         transforms.ColorJitter(brightness=32. / 255., saturation=0.5),\n",
        "                                         transforms.Resize(input_size),\n",
        "                                         transforms.ToTensor(),\n",
        "                                     normalize])\n",
        "\n",
        "val_transform = transforms.Compose([transforms.Resize(input_size),\n",
        "                                    transforms.ToTensor(),\n",
        "                                   normalize])\n",
        "        \n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "\n",
        "train_data_path=img_path = os.path.join(DATA_DIR, 'syntheticDataset/train/images')\n",
        "\n",
        "img_data_train = img_all[x_train,:,:,:]\n",
        "train_set_raw = myDataset(x_train, y_train, img_path=train_data_path, img_data=img_data_train, transform = train_transform)\n",
        "train_dataloader = DataLoader(train_set_raw, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "img_data_val = img_all[x_val,:,:,:]\n",
        "val_set_raw = myDataset(x_val, y_val, img_path=train_data_path, img_data=img_data_val, transform = val_transform)\n",
        "val_dataloader = DataLoader(val_set_raw, batch_size=batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "test_data_path=img_path = os.path.join(DATA_DIR, 'syntheticDataset/test/images')\n",
        "\n",
        "test_set_raw = myDataset(x_test, y_test, img_path=test_data_path, transform = val_transform)\n",
        "test_dataloader = DataLoader(test_set_raw, batch_size=batch_size, shuffle=False, **kwargs)\n"
      ],
      "metadata": {
        "id": "-Q0lz2rqCj21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize data loader"
      ],
      "metadata": {
        "id": "kz-026uR5AYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show dataset sample\n",
        "x,y = test_set_raw[45]\n",
        "#print(x,y)\n",
        "\n",
        "plt.imshow(x.permute(1, 2, 0).numpy())\n",
        "plt.show()\n",
        "\n",
        "# Show batch of images\n",
        "#it = iter(train_dataloader)\n",
        "sample,labels = next(iter(train_dataloader))\n",
        "print(sample.shape)\n",
        "\n",
        "out = torchvision.utils.make_grid(sample)\n",
        "plt.imshow(out.permute(1, 2, 0))\n"
      ],
      "metadata": {
        "id": "gQgnLd4d5MU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning\n",
        "\n",
        "There are several possibilities to solve the problem:\n",
        "\n",
        "* Extract good features and apply a simple predictor. The problem is to find good features for the problem: you know what they can be and how to compute them, or you can rely on \"generic\" features like bag of visual words, histograms or deep features.\n",
        "\n",
        "* Work on raw data and build the label predictor directly. This is typically an approach for deep learning.\n",
        "\n",
        "Notice that the problem is **multi-label prediction**, not classification. Each image may be characterized by several labels.\n"
      ],
      "metadata": {
        "id": "5ctky2b-y3t5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute deep features for images\n",
        "\n",
        "Example of how to compute deep image features. Here, we use a resnext network, but another may be as good and cheaper to compute and store."
      ],
      "metadata": {
        "id": "CSuO94ImmZ5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feat_data_path=os.path.join(DATA_DIR, 'syntheticDataset/train/img_all_feat_resnext.npz')\n",
        "\n",
        "# Checks if features already exist\n",
        "if os.path.exists(feat_data_path):\n",
        "  print(\"Loading image features from \".format(feat_data_path))\n",
        "  feat = np.load(feat_data_path)\n",
        "  feat = feat['img_feat']\n",
        "\n",
        "# If not, compute them\n",
        "else:\n",
        "\n",
        "  print(\"Computing image features\")\n",
        "\n",
        "  from torchvision.models import resnext50_32x4d, ResNeXt50_32X4D_Weights\n",
        "  resnext = torchvision.models.resnext50_32x4d(weights=ResNeXt50_32X4D_Weights.DEFAULT, progress=True)\n",
        "\n",
        "  if device.type == 'cuda':\n",
        "      resnext = resnext.cuda()\n",
        "\n",
        "  model = resnext\n",
        "\n",
        "  # Removes the last classification layer: may different for other network\n",
        "  modules=list(model.children())[:-1]\n",
        "  model=nn.Sequential(*modules)\n",
        "  for p in model.parameters():\n",
        "      p.requires_grad = False\n",
        "\n",
        "  # If you need to put the last layer back\n",
        "  #num_ftrs = resnext.fc.in_features\n",
        "  #resnext.fc = nn.Linear(num_ftrs, 9)\n",
        "\n",
        "  # Uses a dataloader with no data augmentation\n",
        "  all_set_raw = myDataset(x_all, y_all, img_path=train_data_path, img_data=img_all, transform = val_transform)\n",
        "  all_dataloader_feat = DataLoader(all_set_raw, batch_size=200, shuffle=False, **kwargs)\n",
        "\n",
        "  feat = []\n",
        "  for i, data in enumerate(tqdm(all_dataloader_feat)):   ## on itere sur les donnÃ©es \n",
        "      img, targets = data\n",
        "      #print(targets)\n",
        "      if device.type == 'cuda':\n",
        "          img, targets = img.cuda(), targets.cuda()\n",
        "      with torch.no_grad():\n",
        "          outputs = model(img)\n",
        "      if device.type == 'cuda':\n",
        "          feat.append(outputs.cpu().numpy().squeeze())\n",
        "      else:\n",
        "          feat.append(outputs.numpy().squeeze())\n",
        "\n",
        "  feat = np.array(np.concatenate(feat))\n",
        "\n",
        "  print(\"Storing image features in {}\".format(feat_data_path))\n",
        "  np.savez_compressed(feat_data_path, img_feat=feat)\n",
        "\n"
      ],
      "metadata": {
        "id": "uTyrKa_XmaDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning multi-label from pre-computed features"
      ],
      "metadata": {
        "id": "HAaNjGOW-D6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the same random seed to generate the same split\n",
        "feat_train, feat_val, yfeat_train, yfeat_val = train_test_split(feat, y_all, test_size=0.2, random_state=123)\n",
        "\n",
        "print(feat_train.shape)\n",
        "\n",
        "# Chexks if labels are the same as the image split\n",
        "print(np.all(y_val == yfeat_val))\n",
        "\n",
        "# Use your favorite multilabel predictor...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lfwhaJ9S-N3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple network definition\n",
        "\n",
        "An elementary convolutional network with input datasize of 32x32.\n",
        "\n",
        "If you want to  use it, you will need to modify the dataloader. "
      ],
      "metadata": {
        "id": "pJ_CvTAHlPoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# network class\n",
        "class SimpleCNN(nn.Module):\n",
        "# Network requires 32x32 input images  \n",
        "  def __init__(self, nlabel = 10):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    self.nlabel = nlabel\n",
        "    \n",
        "    # define here the convolutions and linear layers\n",
        "    self.conv1 = nn.Conv2d(3,16,3)\n",
        "    self.conv2 = nn.Conv2d(16,32,3)\n",
        "    self.conv3 = nn.Conv2d(32,64,3)\n",
        "    self.lin1 = nn.Linear(256, 128)\n",
        "    self.lin2 = nn.Linear(128, self.nlabel)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    # 32x32\n",
        "    \n",
        "    # define here the forward pass\n",
        "    x1 = self.conv1(x)\n",
        "    x1r = F.relu(x1)\n",
        "    x1p = F.max_pool2d(x1r, 2)\n",
        "    \n",
        "    # 16x16\n",
        "    x2 = self.conv2(x1p)\n",
        "    x2r = F.relu(x2)\n",
        "    x2p = F.max_pool2d(x2r, 2)\n",
        "    \n",
        "    # 8x8\n",
        "    x3 = self.conv3(x2p)\n",
        "    x3r = F.relu(x3)\n",
        "    x3p = F.max_pool2d(x3r, 2)\n",
        "    \n",
        "    # 4x4\n",
        "    y0 = x3p.view(x3p.size(0), -1)\n",
        "    \n",
        "    y1 = self.lin1(y0)\n",
        "    y1r = F.relu(y1)\n",
        "    y2 = self.lin2(y1r)\n",
        "    \n",
        "    return y2\n",
        "    "
      ],
      "metadata": {
        "id": "bgJtYFrPlPx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Another more complex network\n",
        "\n",
        "From torchvision."
      ],
      "metadata": {
        "id": "nqeFbGYY3IHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlabel = y_all.shape[1]\n",
        "\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "network = torchvision.models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "num_ftrs = network.classifier[1].in_features\n",
        "network.classifier[1]= nn.Linear(num_ftrs, nlabel)\n",
        "\n",
        "# Name of the network\n",
        "tag = \"efficientNet\"\n",
        "\n",
        "# network = SimpleCNN(nlabel = nlabel)\n",
        "# # Name of the network\n",
        "# tag = \"simpleCNN\"\n"
      ],
      "metadata": {
        "id": "xsY9wiqRKjEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning\n",
        "\n",
        "Generic function for multi-label learning.\n",
        "\n",
        "You have to write it!!"
      ],
      "metadata": {
        "id": "HPQFXgNCIXB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import confusion_matrix\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import copy\n",
        "\n",
        "def train_model_multilabel(model, nlabel, trainloader, valloader, criterion, optimizer, scheduler, num_epochs=5):\n",
        "\n",
        "    # list for saving accuracies\n",
        "    train_perf = []\n",
        "    test_perf = []\n",
        "    train_losses = []\n",
        "    \n",
        "    # iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "      print(\"Epoch {}\".format(epoch))\n",
        "\n",
        "      # Learning step\n",
        "\n",
        "    return model, train_perf, test_perf, train_losses\n",
        "\n"
      ],
      "metadata": {
        "id": "_a3NiZTTzBY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of a code calling the learning function"
      ],
      "metadata": {
        "id": "2vpZwQSx8sId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data loaders\n",
        "trainloader=train_dataloader\n",
        "valloader=val_dataloader\n",
        "\n",
        "# Read the last learned network (if stored)\n",
        "if (os.path.exists(os.path.join(img_path, 'network_{:s}.pth'.format(tag)))):\n",
        "    print('Resume from last learning step')\n",
        "    network = torch.load(os.path.join(img_path, 'network_{:s}.pth'.format(tag)))\n",
        "\n",
        "# Transfer network to GPU\n",
        "network.to(device)\n",
        "\n",
        "# Define learning components (to be used in the learning function)\n",
        "#criterion = ...\n",
        "#optimizer = ...\n",
        "#scheduler = ...\n",
        "\n",
        "# Learning \n",
        "\n",
        "max_epoch = 20\n",
        "learned_model, train_error, test_error, train_losses = train_model_multilabel(network, nlabel, trainloader, valloader, criterion, optimizer, scheduler, num_epochs=max_epoch)\n",
        "torch.save(learned_model, os.path.join(img_path, 'network_{:s}.pth'.format(tag)))\n",
        "\n",
        "network = learned_model\n",
        "\n",
        "print(\"Train accuracies\")\n",
        "print(train_error)\n",
        "print(\"Test accuracies\")\n",
        "print(test_error)\n",
        "print(\"Train losses\")\n",
        "print(train_losses)\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-02-14T08:08:30.852745Z",
          "iopub.execute_input": "2022-02-14T08:08:30.857727Z",
          "iopub.status.idle": "2022-02-14T09:21:30.644427Z",
          "shell.execute_reply.started": "2022-02-14T08:08:30.857688Z",
          "shell.execute_reply": "2022-02-14T09:21:30.643587Z"
        },
        "trusted": true,
        "id": "eiFzwRKuqfWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final evaluation\n",
        "\n",
        "An example of performance computation.\n",
        "\n",
        "Again, the problem is multi-label prediction, not classification: performance metrics may be different (make a little search to find relevant ones)."
      ],
      "metadata": {
        "id": "WGnwwzhFxWYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testloader = test_dataloader\n",
        "\n",
        "\n",
        "# set the model to evaluation mode\n",
        "network.eval()\n",
        "\n",
        "# create the per\n",
        "perf_label_test = np.zeros((1,nlabel))\n",
        "\n",
        "# tell not to reserve memory space for gradients (much faster)\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in tqdm(testloader, ncols=80):\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # compute outputs\n",
        "        outputs = network(inputs)\n",
        "\n",
        "        outputs_np = outputs.cpu().detach().numpy()\n",
        "        targets_np = targets.cpu().detach().numpy()\n",
        "\n",
        "        # compute the predictions\n",
        "        pred = (outputs_np > 0)\n",
        "\n",
        "        # update the performance\n",
        "        perf_label_test = perf_label_test + (targets_np == pred).sum(axis=0)\n",
        "\n",
        "# Prints the performance (per label)\n",
        "\n",
        "oa_test = perf_label_test / len(testloader.dataset)\n",
        "print(oa_test)"
      ],
      "metadata": {
        "id": "vPwTfkyLxU_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}